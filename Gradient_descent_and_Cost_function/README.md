# Machine Learning (Gradient Descent and Cost Function)

Gradient Descent:
Gradient Descent is an iterative optimization algorithm used to find the minimum (or maximum) of a function. It is widely used in machine learning and deep learning to update the parameters of a model in order to minimize a cost function and improve the model's performance. The concept behind Gradient Descent is to take steps in the direction of the steepest slope (gradient) of the cost function in order to reach the optimal solution.

The learning rate is a crucial hyperparameter in the Gradient Descent algorithm. If the learning rate is too small, the algorithm may converge very slowly. On the other hand, if it is too large, the algorithm may overshoot the optimal solution and fail to converge.

Cost Function:
In the context of machine learning, a cost function, also known as a loss function or objective function, measures how well a model's predictions match the actual target values. The goal of training a machine learning model is to minimize the value of the cost function. In other words, it quantifies the error or discrepancy between the predicted outputs of the model and the true labels in the training data.

In summary, Gradient Descent is an optimization algorithm that iteratively updates model parameters to minimize a cost function, which quantifies the model's error. It is a fundamental concept in training machine learning models and is used in various algorithms to find optimal solutions for a wide range of problems.
